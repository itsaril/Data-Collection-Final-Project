[2025-12-16T13:03:29.037+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: job2_weather_cleaning.clean_and_store_weather manual__2025-12-16T13:03:25.991411+00:00 [queued]>
[2025-12-16T13:03:29.059+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: job2_weather_cleaning.clean_and_store_weather manual__2025-12-16T13:03:25.991411+00:00 [queued]>
[2025-12-16T13:03:29.062+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 3
[2025-12-16T13:03:29.115+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): clean_and_store_weather> on 2025-12-16 13:03:25.991411+00:00
[2025-12-16T13:03:29.139+0000] {standard_task_runner.py:57} INFO - Started process 843 to run task
[2025-12-16T13:03:29.153+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'job2_weather_cleaning', 'clean_and_store_weather', 'manual__2025-12-16T13:03:25.991411+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/job2_clean_store_dag.py', '--cfg-path', '/tmp/tmpf45v9kk0']
[2025-12-16T13:03:29.166+0000] {standard_task_runner.py:85} INFO - Job 37: Subtask clean_and_store_weather
[2025-12-16T13:03:29.385+0000] {task_command.py:416} INFO - Running <TaskInstance: job2_weather_cleaning.clean_and_store_weather manual__2025-12-16T13:03:25.991411+00:00 [running]> on host 368de0f02f1d
[2025-12-16T13:03:29.662+0000] {taskinstance.py:1662} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='team' AIRFLOW_CTX_DAG_ID='job2_weather_cleaning' AIRFLOW_CTX_TASK_ID='clean_and_store_weather' AIRFLOW_CTX_EXECUTION_DATE='2025-12-16T13:03:25.991411+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-12-16T13:03:25.991411+00:00'
[2025-12-16T13:03:29.694+0000] {logging_mixin.py:154} INFO - Database initialized at /opt/***/data/app.db
[2025-12-16T13:03:29.705+0000] {conn.py:380} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.18.0.4', 29092)]>: connecting to kafka:29092 [('172.18.0.4', 29092) IPv4]
[2025-12-16T13:03:29.707+0000] {conn.py:1205} INFO - Probing node bootstrap-0 broker version
[2025-12-16T13:03:29.710+0000] {conn.py:410} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connecting> [IPv4 ('172.18.0.4', 29092)]>: Connection complete.
[2025-12-16T13:03:29.838+0000] {conn.py:1267} INFO - Broker version identified as 2.5.0
[2025-12-16T13:03:29.848+0000] {conn.py:1268} INFO - Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup
[2025-12-16T13:03:29.860+0000] {subscription_state.py:171} INFO - Updating subscribed topics to: ('raw_weather_events',)
[2025-12-16T13:03:29.866+0000] {logging_mixin.py:154} INFO - Starting to consume messages from Kafka...
[2025-12-16T13:03:29.891+0000] {cluster.py:371} INFO - Group coordinator for weather_cleaner_group is ('coordinator-1', 'kafka', 29092, None)
[2025-12-16T13:03:29.897+0000] {base.py:693} INFO - Discovered coordinator coordinator-1 for group weather_cleaner_group
[2025-12-16T13:03:29.899+0000] {base.py:741} INFO - Starting new heartbeat thread
[2025-12-16T13:03:29.906+0000] {consumer.py:348} INFO - Revoking previously assigned partitions () for group weather_cleaner_group
[2025-12-16T13:03:29.910+0000] {conn.py:380} INFO - <BrokerConnection node_id=coordinator-1 host=kafka:29092 <connecting> [IPv4 ('172.18.0.4', 29092)]>: connecting to kafka:29092 [('172.18.0.4', 29092) IPv4]
[2025-12-16T13:03:29.916+0000] {conn.py:410} INFO - <BrokerConnection node_id=coordinator-1 host=kafka:29092 <connecting> [IPv4 ('172.18.0.4', 29092)]>: Connection complete.
[2025-12-16T13:03:29.929+0000] {conn.py:919} INFO - <BrokerConnection node_id=bootstrap-0 host=kafka:29092 <connected> [IPv4 ('172.18.0.4', 29092)]>: Closing connection. 
[2025-12-16T13:03:30.031+0000] {base.py:450} INFO - (Re-)joining group weather_cleaner_group
[2025-12-16T13:03:33.043+0000] {base.py:521} INFO - Elected group leader -- performing partition assignments using range
[2025-12-16T13:03:33.047+0000] {conn.py:380} INFO - <BrokerConnection node_id=1 host=kafka:29092 <connecting> [IPv4 ('172.18.0.4', 29092)]>: connecting to kafka:29092 [('172.18.0.4', 29092) IPv4]
[2025-12-16T13:03:33.049+0000] {conn.py:410} INFO - <BrokerConnection node_id=1 host=kafka:29092 <connecting> [IPv4 ('172.18.0.4', 29092)]>: Connection complete.
[2025-12-16T13:03:33.067+0000] {base.py:335} INFO - Successfully joined group weather_cleaner_group with generation 17
[2025-12-16T13:03:33.069+0000] {subscription_state.py:257} INFO - Updated partition assignment: [('raw_weather_events', 0)]
[2025-12-16T13:03:33.070+0000] {consumer.py:245} INFO - Setting newly assigned partitions (('raw_weather_events', 0),) for group weather_cleaner_group
[2025-12-16T13:03:33.086+0000] {logging_mixin.py:154} INFO - Consumed message: Shymkent at 2025-12-16T13:00:00Z
[2025-12-16T13:03:33.087+0000] {logging_mixin.py:154} INFO - Consumed message: Almaty at 2025-12-16T13:00:00Z
[2025-12-16T13:03:33.088+0000] {logging_mixin.py:154} INFO - Consumed message: Astana at 2025-12-16T13:00:00Z
[2025-12-16T13:03:33.089+0000] {logging_mixin.py:154} INFO - Consumed message: Shymkent at 2025-12-16T13:01:00Z
[2025-12-16T13:03:33.089+0000] {logging_mixin.py:154} INFO - Consumed message: Almaty at 2025-12-16T13:01:00Z
[2025-12-16T13:03:33.090+0000] {logging_mixin.py:154} INFO - Consumed message: Astana at 2025-12-16T13:01:00Z
[2025-12-16T13:03:33.090+0000] {logging_mixin.py:154} INFO - Consumed message: Shymkent at 2025-12-16T13:01:00Z
[2025-12-16T13:03:33.091+0000] {logging_mixin.py:154} INFO - Consumed message: Almaty at 2025-12-16T13:02:00Z
[2025-12-16T13:03:33.091+0000] {logging_mixin.py:154} INFO - Consumed message: Astana at 2025-12-16T13:02:00Z
[2025-12-16T13:03:33.092+0000] {logging_mixin.py:154} INFO - Consumed message: Shymkent at 2025-12-16T13:02:00Z
[2025-12-16T13:03:33.093+0000] {logging_mixin.py:154} INFO - Consumed message: Almaty at 2025-12-16T13:03:00Z
[2025-12-16T13:03:33.093+0000] {logging_mixin.py:154} INFO - Consumed message: Astana at 2025-12-16T13:03:00Z
[2025-12-16T13:03:33.094+0000] {logging_mixin.py:154} INFO - Consumed message: Shymkent at 2025-12-16T13:03:00Z
[2025-12-16T13:03:43.102+0000] {base.py:748} INFO - Stopping heartbeat thread
[2025-12-16T13:03:43.104+0000] {base.py:773} INFO - Leaving consumer group (weather_cleaner_group).
[2025-12-16T13:03:43.113+0000] {conn.py:919} INFO - <BrokerConnection node_id=coordinator-1 host=kafka:29092 <connected> [IPv4 ('172.18.0.4', 29092)]>: Closing connection. 
[2025-12-16T13:03:43.115+0000] {conn.py:919} INFO - <BrokerConnection node_id=1 host=kafka:29092 <connected> [IPv4 ('172.18.0.4', 29092)]>: Closing connection. 
[2025-12-16T13:03:43.117+0000] {future.py:79} ERROR - Fetch to node 1 failed: Cancelled: <BrokerConnection node_id=1 host=kafka:29092 <connected> [IPv4 ('172.18.0.4', 29092)]>
[2025-12-16T13:03:43.118+0000] {logging_mixin.py:154} INFO - 
Total messages consumed: 13
[2025-12-16T13:03:43.126+0000] {logging_mixin.py:154} INFO - Initial records: 13
[2025-12-16T13:03:43.133+0000] {logging_mixin.py:154} INFO - After removing duplicates: 12
[2025-12-16T13:03:43.148+0000] {logging_mixin.py:154} INFO - After removing invalid timestamps: 12
[2025-12-16T13:03:43.153+0000] {logging_mixin.py:154} INFO - After range validation: 12
[2025-12-16T13:03:43.162+0000] {logging_mixin.py:154} INFO - Final cleaned records: 12
[2025-12-16T13:03:43.252+0000] {logging_mixin.py:154} INFO - Inserted 12 records into events table
[2025-12-16T13:03:43.253+0000] {logging_mixin.py:154} INFO - Successfully inserted 12 cleaned records
[2025-12-16T13:03:43.255+0000] {python.py:194} INFO - Done. Returned value was: None
[2025-12-16T13:03:43.284+0000] {taskinstance.py:1400} INFO - Marking task as SUCCESS. dag_id=job2_weather_cleaning, task_id=clean_and_store_weather, execution_date=20251216T130325, start_date=20251216T130329, end_date=20251216T130343
[2025-12-16T13:03:43.384+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 0
[2025-12-16T13:03:43.418+0000] {taskinstance.py:2778} INFO - 0 downstream tasks scheduled from follow-on schedule check
